import os
import re
import asyncio
from playwright.async_api import async_playwright
from bs4 import BeautifulSoup
import config

# íˆìŠ¤í† ë¦¬ ê´€ë¦¬ í•¨ìˆ˜
def manage_history(new_title):
    history = []
    # íŒŒì¼ì´ ì—†ìœ¼ë©´ ìƒì„±
    if not os.path.exists(config.HISTORY_FILE):
        with open(config.HISTORY_FILE, "w", encoding="utf-8") as f:
            pass

    with open(config.HISTORY_FILE, "r", encoding="utf-8") as f:
        history = [line.strip() for line in f if line.strip()]

    if new_title in history:
        return True # ì´ë¯¸ ì¡´ì¬í•¨ (ì¤‘ë³µ)

    # ìƒˆ íƒ€ì´í‹€ ì¶”ê°€ ë° 30ê°œ ìœ ì§€
    history.append(new_title)
    if len(history) > 30:
        history = history[-30:]

    with open(config.HISTORY_FILE, "w", encoding="utf-8") as f:
        for title in history:
            f.write(title + "\n")
    return False

async def get_borussia_news(ignore_history=False): # í…ŒìŠ¤íŠ¸ë¥¼ ìœ„í•´ ignore_history ì˜µì…˜ ì¶”ê°€
    async with async_playwright() as p:
        print("ğŸš€ ë¸Œë¼ìš°ì € ì‹¤í–‰ ì¤‘...")
        browser = await p.chromium.launch(headless=True)
        context = await browser.new_context(
            user_agent="Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/143.0.0.0 Safari/537.36",
            viewport={'width': 1280, 'height': 1200}
        )
        page = await context.new_page()

        print("ğŸŒ ë‰´ìŠ¤ ëª©ë¡ í˜ì´ì§€ ì ‘ì† ì¤‘...")
        try:
            await page.goto("https://www.borussia.de/news", wait_until="networkidle", timeout=60000)
        except Exception as e:
            print(f"âš ï¸ í˜ì´ì§€ ë¡œë”© ì‹œê°„ ì´ˆê³¼ ë˜ëŠ” ì—ëŸ¬: {e}")
            # ì—ëŸ¬ê°€ ë‚˜ë„ ì¼ë‹¨ ì§„í–‰í•´ë´…ë‹ˆë‹¤ (ì¼ë¶€ ë¡œë”©ëì„ ìˆ˜ ìˆìŒ)

        # ìŠ¤í¬ë¡¤ì„ ì¢€ ë” í™•ì‹¤í•˜ê²Œ ì—¬ëŸ¬ ë²ˆ ë‚´ë¦¼
        for _ in range(3):
            await page.mouse.wheel(0, 1500)
            await asyncio.sleep(1)

        # ë””ë²„ê¹…: í˜„ì¬ í˜ì´ì§€ íƒ€ì´í‹€ í™•ì¸
        page_title = await page.title()
        print(f"ğŸ” ì ‘ì†ëœ í˜ì´ì§€ ì œëª©: {page_title}")

        list_content = await page.content()
        list_soup = BeautifulSoup(list_content, 'html.parser')
        
        # ì„ íƒì í™•ì¸
        articles = list_soup.select('a[href^="/news/"]')
        print(f"ğŸ“Š ë°œê²¬ëœ ê¸°ì‚¬ ë§í¬ ìˆ˜: {len(articles)}ê°œ")

        if len(articles) == 0:
            print("âŒ ê¸°ì‚¬ë¥¼ í•˜ë‚˜ë„ ëª» ì°¾ì•˜ìŠµë‹ˆë‹¤. ì„ íƒì(a[href^='/news/'])ê°€ ë§ì§€ ì•Šê±°ë‚˜ í˜ì´ì§€ê°€ ëœ ë¡œë”©ë˜ì—ˆìŠµë‹ˆë‹¤.")
            await browser.close()
            return []

        final_task_list = []

        # ìƒìœ„ 5ê°œë§Œ ê²€í† 
        for i, a in enumerate(articles[:5]):
            title = a.select_one('h3').get_text(strip=True) if a.select_one('h3') else "ì œëª© ì—†ìŒ"
            full_url = f"https://www.borussia.de{a['href']}"
            
            print(f"   [{i+1}] ê²€í†  ì¤‘: {title}")

            # ignore_historyê°€ Trueë©´ ì¤‘ë³µ ì²´í¬ë¥¼ ê±´ë„ˆëœ€ (ë¬´ì¡°ê±´ ìˆ˜ì§‘)
            if not ignore_history:
                if manage_history(title):
                    print(f"      â­ï¸ [ìŠ¤í‚µ] ì´ë¯¸ íˆìŠ¤í† ë¦¬ì— ì¡´ì¬í•¨")
                    continue
            else:
                print(f"      âš¡ [í…ŒìŠ¤íŠ¸ ëª¨ë“œ] íˆìŠ¤í† ë¦¬ ë¬´ì‹œí•˜ê³  ìˆ˜ì§‘ ì§„í–‰")

            # ìƒì„¸ ìˆ˜ì§‘ ì‹œì‘
            try:
                print(f"      âœ… ìƒì„¸ í˜ì´ì§€ ì´ë™ ì¤‘...")
                await page.goto(full_url, wait_until="domcontentloaded", timeout=60000)
                
                # ë³¸ë¬¸ ëŒ€ê¸°
                try: await page.wait_for_selector("article", timeout=5000)
                except: pass

                # ë³¸ë¬¸ ì¶”ì¶œ ì‹œë„
                content = ""
                content_el = await page.query_selector("article")
                if content_el: 
                    content = (await content_el.inner_text()).strip()
                
                if not content:
                    content_el = await page.query_selector(".news-detail__content")
                    if content_el: content = (await content_el.inner_text()).strip()

                if not content:
                    # ìµœí›„ì˜ ìˆ˜ë‹¨: ë³¸ë¬¸ì´ ì—†ìœ¼ë©´ ê·¸ëƒ¥ body ì „ì²´ ê¸ê¸° (í…ŒìŠ¤íŠ¸ìš©)
                    content = await page.evaluate("() => document.body.innerText")
                    content = content[:500] + "..." # ë„ˆë¬´ ê¸°ë‹ˆê¹Œ ìë¥´ê¸°

                # ì´ë¯¸ì§€ ìº¡ì²˜
                clean_title = re.sub(r'[\\/*?:"<>|]', "", title).strip()
                image_path = f"{config.IMAGE_DIR}/{clean_title}.png"
                await page.screenshot(path=image_path, clip={'x': 40, 'y': 100, 'width': 1200, 'height': 600})

                final_task_list.append({
                    'title': title,
                    'link': full_url,
                    'content': content,
                    'image_path': image_path
                })
                print(f"      ğŸ“„ ìˆ˜ì§‘ ì™„ë£Œ (ë³¸ë¬¸ ê¸¸ì´: {len(content)})")

            except Exception as e:
                print(f"      âŒ ìƒì„¸ í˜ì´ì§€ ì²˜ë¦¬ ì—ëŸ¬: {e}")

        await browser.close()

        return final_task_list
